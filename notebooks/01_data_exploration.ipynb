{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Data Exploration - Retail Customer Analytics\n",
    "\n",
    "This notebook provides comprehensive exploratory data analysis (EDA) of the retail customer dataset.\n",
    "\n",
    "## Objectives:\n",
    "- Load and examine the raw customer data\n",
    "- Understand data structure, types, and quality\n",
    "- Identify patterns, trends, and anomalies\n",
    "- Generate initial insights for business stakeholders\n",
    "- Prepare data quality assessment for preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"ðŸ“š Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Option 1: Load from Kaggle dataset\n",
    "# df = pd.read_csv('https://www.kaggle.com/datasets/iamsouravbanerjee/customer-shopping-trends-dataset')\n",
    "\n",
    "# Option 2: Load from local file\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/customer_shopping_data.csv')\n",
    "    print(f\"âœ… Dataset loaded successfully!\")\n",
    "    print(f\"ðŸ“ Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Dataset file not found. Using sample data generator...\")\n",
    "    # Use our sample data generator\n",
    "    import sys\n",
    "    sys.path.append('../src')\n",
    "    from utils.common import load_sample_data\n",
    "    df = load_sample_data(n_customers=2000)\n",
    "    print(f\"âœ… Sample dataset generated successfully!\")\n",
    "    print(f\"ðŸ“ Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"ðŸ“‹ DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of records: {len(df):,}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nðŸ“Š COLUMN INFORMATION:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"ðŸ” FIRST 5 ROWS:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nðŸ” LAST 5 ROWS:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"ðŸ“ˆ STATISTICAL SUMMARY - NUMERICAL FEATURES:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nðŸ“ STATISTICAL SUMMARY - CATEGORICAL FEATURES:\")\n",
    "display(df.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing Percentage': missing_percentage.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"â“ MISSING VALUES ANALYSIS:\")\n",
    "display(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing_df['Missing Count'].sum() == 0:\n",
    "    print(\"âœ… No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"ðŸ”„ DUPLICATE RECORDS: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"âš ï¸ Found {duplicates} duplicate records ({duplicates/len(df)*100:.2f}% of data)\")\n",
    "    # Show duplicate examples\n",
    "    print(\"\\nExamples of duplicate records:\")\n",
    "    display(df[df.duplicated(keep=False)].head())\n",
    "else:\n",
    "    print(\"âœ… No duplicate records found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type analysis\n",
    "dtype_summary = df.dtypes.value_counts()\n",
    "print(\"ðŸ·ï¸ DATA TYPES SUMMARY:\")\n",
    "for dtype, count in dtype_summary.items():\n",
    "    print(f\"  {dtype}: {count} columns\")\n",
    "\n",
    "# Identify potential data type issues\n",
    "print(\"\\nðŸ” POTENTIAL DATA TYPE ISSUES:\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        # Check if numeric data is stored as object\n",
    "        try:\n",
    "            pd.to_numeric(df[col])\n",
    "            print(f\"  âš ï¸ {col}: Stored as object but appears to be numeric\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Check for date columns\n",
    "    if 'date' in col.lower() and df[col].dtype == 'object':\n",
    "        print(f\"  ðŸ“… {col}: Appears to be a date column but stored as object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features distribution\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"ðŸ“Š ANALYZING {len(numerical_cols)} NUMERICAL FEATURES:\")\n",
    "print(list(numerical_cols))\n",
    "\n",
    "# Create distribution plots\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        if i < len(axes):\n",
    "            df[col].hist(bins=30, ax=axes[i], alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(numerical_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"ðŸ“ ANALYZING {len(categorical_cols)} CATEGORICAL FEATURES:\")\n",
    "print(list(categorical_cols))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nðŸ·ï¸ {col}:\")\n",
    "    value_counts = df[col].value_counts()\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Most frequent: {value_counts.index[0]} ({value_counts.iloc[0]} occurrences)\")\n",
    "    \n",
    "    if df[col].nunique() <= 10:  # Show all values if <= 10 unique\n",
    "        print(\"  Value distribution:\")\n",
    "        for val, count in value_counts.items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"    {val}: {count} ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  Top 5 values: {list(value_counts.head().index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive categorical distribution plots\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols[:4]:  # Limit to first 4 categorical columns\n",
    "        if df[col].nunique() <= 20:  # Only plot if reasonable number of categories\n",
    "            fig = px.bar(\n",
    "                x=df[col].value_counts().index,\n",
    "                y=df[col].value_counts().values,\n",
    "                title=f'Distribution of {col}',\n",
    "                labels={'x': col, 'y': 'Count'}\n",
    "            )\n",
    "            fig.update_layout(height=400)\n",
    "            fig.show()\n",
    "        else:\n",
    "            print(f\"âš ï¸ Skipping {col} - too many categories ({df[col].nunique()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key business insights\n",
    "print(\"ðŸ’¡ KEY BUSINESS INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Find key columns\n",
    "customer_col = 'Customer ID' if 'Customer ID' in df.columns else None\n",
    "amount_col = next((col for col in df.columns if 'amount' in col.lower() or 'price' in col.lower()), None)\n",
    "category_col = next((col for col in df.columns if 'category' in col.lower()), None)\n",
    "age_col = next((col for col in df.columns if 'age' in col.lower()), None)\n",
    "\n",
    "# Customer insights\n",
    "if customer_col:\n",
    "    unique_customers = df[customer_col].nunique()\n",
    "    total_transactions = len(df)\n",
    "    avg_transactions_per_customer = total_transactions / unique_customers\n",
    "    \n",
    "    insights.append(f\"ðŸ‘¥ Customer Base: {unique_customers:,} unique customers\")\n",
    "    insights.append(f\"ðŸ›’ Average transactions per customer: {avg_transactions_per_customer:.1f}\")\n",
    "\n",
    "# Revenue insights\n",
    "if amount_col:\n",
    "    total_revenue = df[amount_col].sum()\n",
    "    avg_transaction_value = df[amount_col].mean()\n",
    "    median_transaction_value = df[amount_col].median()\n",
    "    \n",
    "    insights.append(f\"ðŸ’° Total revenue: ${total_revenue:,.2f}\")\n",
    "    insights.append(f\"ðŸ’³ Average transaction value: ${avg_transaction_value:.2f}\")\n",
    "    insights.append(f\"ðŸ’³ Median transaction value: ${median_transaction_value:.2f}\")\n",
    "\n",
    "# Category insights\n",
    "if category_col:\n",
    "    top_category = df[category_col].value_counts().index[0]\n",
    "    top_category_count = df[category_col].value_counts().iloc[0]\n",
    "    category_percentage = (top_category_count / len(df)) * 100\n",
    "    \n",
    "    insights.append(f\"ðŸ† Most popular category: {top_category} ({category_percentage:.1f}% of transactions)\")\n",
    "    insights.append(f\"ðŸ“ Total categories: {df[category_col].nunique()}\")\n",
    "\n",
    "# Age insights (if available)\n",
    "if age_col:\n",
    "    avg_age = df[age_col].mean()\n",
    "    median_age = df[age_col].median()\n",
    "    age_range = df[age_col].max() - df[age_col].min()\n",
    "    \n",
    "    insights.append(f\"ðŸ‘¶ Customer age - Average: {avg_age:.1f}, Median: {median_age:.1f}, Range: {age_range}\")\n",
    "\n",
    "# Data quality insights\n",
    "completeness = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
    "insights.append(f\"âœ… Data completeness: {completeness:.1f}%\")\n",
    "\n",
    "# Print insights\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i:2d}. {insight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ðŸ“‹ RECOMMENDATIONS FOR NEXT STEPS:\")\n",
    "print(\"1. ðŸ§¹ Data Preprocessing: Address missing values and duplicates\")\n",
    "print(\"2. ðŸ”§ Feature Engineering: Create RFM features, customer segments\")\n",
    "print(\"3. ðŸ“Š Advanced Analytics: Customer segmentation, churn prediction\")\n",
    "print(\"4. ðŸ¤– Machine Learning: Recommendation systems, CLV prediction\")\n",
    "print(\"5. ðŸ“ˆ Business Intelligence: Dashboard creation, KPI monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exploration results\n",
    "try:\n",
    "    # Create summary statistics file\n",
    "    summary_stats = df.describe(include='all')\n",
    "    summary_stats.to_csv('../reports/analysis/01_exploration_summary.csv')\n",
    "    \n",
    "    # Save data quality report\n",
    "    quality_report = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Data_Type': df.dtypes,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "        'Unique_Values': [df[col].nunique() for col in df.columns]\n",
    "    })\n",
    "    quality_report.to_csv('../reports/analysis/01_data_quality_report.csv', index=False)\n",
    "    \n",
    "    print(\"ðŸ’¾ Reports saved to ../reports/analysis/\")\n",
    "    print(\"   - 01_exploration_summary.csv\")\n",
    "    print(\"   - 01_data_quality_report.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not save reports: {e}\")\n",
    "\n",
    "print(\"\\nâœ… DATA EXPLORATION COMPLETED!\")\n",
    "print(\"\\nðŸš€ Ready for next notebook: 02_eda_insights.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}