{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üë• Customer Segmentation - Advanced Analytics\n",
    "\n",
    "This notebook focuses on customer segmentation using various clustering techniques and RFM analysis.\n",
    "\n",
    "## Objectives:\n",
    "- Implement RFM (Recency, Frequency, Monetary) analysis\n",
    "- Apply K-Means clustering for customer segmentation\n",
    "- Explore hierarchical clustering techniques\n",
    "- Analyze customer segments and create personas\n",
    "- Develop targeted marketing strategies\n",
    "- Validate segmentation results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from components.customer_segmentation import CustomerSegmentation\n",
    "\n",
    "print(\"üìö Customer segmentation libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "    print(f\"‚úÖ Cleaned dataset loaded: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"üìä Loading raw data for processing...\")\n",
    "    try:\n",
    "        df = pd.read_csv('../data/raw/customer_shopping_data.csv')\n",
    "    except FileNotFoundError:\n",
    "        from utils.common import load_sample_data\n",
    "        df = load_sample_data(n_customers=2000)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nüìã Dataset Overview:\")\n",
    "print(f\"Records: {len(df):,}\")\n",
    "if 'Customer ID' in df.columns:\n",
    "    print(f\"Unique Customers: {df['Customer ID'].nunique():,}\")\n",
    "print(f\"Features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for clustering\n",
    "def prepare_segmentation_features(df):\n",
    "    \"\"\"Prepare features for customer segmentation\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Customer-level aggregation\n",
    "    if 'Customer ID' in df.columns:\n",
    "        customer_features = df.groupby('Customer ID').agg({\n",
    "            'Purchase Amount (USD)': ['sum', 'mean', 'count', 'std'] if 'Purchase Amount (USD)' in df.columns else None,\n",
    "            'Age': 'first' if 'Age' in df.columns else None,\n",
    "            'Review Rating': 'mean' if 'Review Rating' in df.columns else None,\n",
    "            'Category': 'nunique' if 'Category' in df.columns else None\n",
    "        }).fillna(0)\n",
    "        \n",
    "        # Flatten column names\n",
    "        customer_features.columns = ['_'.join(col).strip() for col in customer_features.columns.values]\n",
    "        customer_features = customer_features.reset_index()\n",
    "        \n",
    "        features = customer_features\n",
    "    else:\n",
    "        # Use individual transaction features if no customer ID\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        features = df[numeric_cols].fillna(0)\n",
    "    \n",
    "    print(f\"üìä Features prepared: {features.shape}\")\n",
    "    print(f\"Feature columns: {list(features.columns)}\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "features_df = prepare_segmentation_features(df)\n",
    "display(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RFM features\n",
    "def create_rfm_features(df):\n",
    "    \"\"\"Create RFM (Recency, Frequency, Monetary) features\"\"\"\n",
    "    \n",
    "    if 'Customer ID' not in df.columns:\n",
    "        print(\"‚ö†Ô∏è Customer ID not found. Creating synthetic RFM data...\")\n",
    "        # Create synthetic RFM data\n",
    "        n_customers = min(1000, len(df))\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        rfm_df = pd.DataFrame({\n",
    "            'Customer_ID': [f'CUST_{i:05d}' for i in range(n_customers)],\n",
    "            'Recency': np.random.exponential(30, n_customers),  # Days since last purchase\n",
    "            'Frequency': np.random.poisson(5, n_customers),     # Number of purchases\n",
    "            'Monetary': np.random.exponential(200, n_customers) # Total spend\n",
    "        })\n",
    "    else:\n",
    "        # Calculate actual RFM from data\n",
    "        reference_date = pd.to_datetime('2024-01-01')  # Use a reference date\n",
    "        \n",
    "        if 'Purchase Date' in df.columns:\n",
    "            df['Purchase Date'] = pd.to_datetime(df['Purchase Date'])\n",
    "            \n",
    "            rfm_df = df.groupby('Customer ID').agg({\n",
    "                'Purchase Date': lambda x: (reference_date - x.max()).days,\n",
    "                'Customer ID': 'count',\n",
    "                'Purchase Amount (USD)': 'sum' if 'Purchase Amount (USD)' in df.columns else None\n",
    "            })\n",
    "            \n",
    "            rfm_df.columns = ['Recency', 'Frequency', 'Monetary']\n",
    "            rfm_df = rfm_df.reset_index()\n",
    "        else:\n",
    "            # Use aggregated features as proxy\n",
    "            if 'Purchase Amount (USD)' in df.columns:\n",
    "                customer_agg = df.groupby('Customer ID').agg({\n",
    "                    'Purchase Amount (USD)': ['sum', 'count']\n",
    "                })\n",
    "                customer_agg.columns = ['Monetary', 'Frequency']\n",
    "                customer_agg['Recency'] = np.random.exponential(30, len(customer_agg))\n",
    "                rfm_df = customer_agg.reset_index()\n",
    "            else:\n",
    "                # Fallback to synthetic data\n",
    "                n_customers = df['Customer ID'].nunique()\n",
    "                rfm_df = pd.DataFrame({\n",
    "                    'Customer ID': df['Customer ID'].unique(),\n",
    "                    'Recency': np.random.exponential(30, n_customers),\n",
    "                    'Frequency': np.random.poisson(5, n_customers),\n",
    "                    'Monetary': np.random.exponential(200, n_customers)\n",
    "                })\n",
    "    \n",
    "    print(f\"‚úÖ RFM features created for {len(rfm_df)} customers\")\n",
    "    return rfm_df\n",
    "\n",
    "rfm_data = create_rfm_features(df)\n",
    "display(rfm_data.head())\n",
    "display(rfm_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RFM Analysis and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM Scoring and Segmentation\n",
    "def create_rfm_segments(rfm_df):\n",
    "    \"\"\"Create RFM segments based on quintile scoring\"\"\"\n",
    "    \n",
    "    # Create RFM scores (quintiles)\n",
    "    rfm_df['R_Score'] = pd.qcut(rfm_df['Recency'].rank(method='first'), 5, labels=[5,4,3,2,1])  # Lower recency = higher score\n",
    "    rfm_df['F_Score'] = pd.qcut(rfm_df['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])  # Higher frequency = higher score\n",
    "    rfm_df['M_Score'] = pd.qcut(rfm_df['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5])   # Higher monetary = higher score\n",
    "    \n",
    "    # Convert to integers\n",
    "    rfm_df['R_Score'] = rfm_df['R_Score'].astype(int)\n",
    "    rfm_df['F_Score'] = rfm_df['F_Score'].astype(int)\n",
    "    rfm_df['M_Score'] = rfm_df['M_Score'].astype(int)\n",
    "    \n",
    "    # Create RFM combined score\n",
    "    rfm_df['RFM_Score'] = rfm_df['R_Score'].astype(str) + rfm_df['F_Score'].astype(str) + rfm_df['M_Score'].astype(str)\n",
    "    \n",
    "    # Define segment rules\n",
    "    def assign_segment(row):\n",
    "        if row['R_Score'] >= 4 and row['F_Score'] >= 4 and row['M_Score'] >= 4:\n",
    "            return 'Champions'\n",
    "        elif row['R_Score'] >= 3 and row['F_Score'] >= 3 and row['M_Score'] >= 3:\n",
    "            return 'Loyal Customers'\n",
    "        elif row['R_Score'] >= 4 and row['F_Score'] <= 2:\n",
    "            return 'New Customers'\n",
    "        elif row['R_Score'] >= 3 and row['F_Score'] <= 2 and row['M_Score'] >= 3:\n",
    "            return 'Potential Loyalists'\n",
    "        elif row['R_Score'] <= 2 and row['F_Score'] >= 3 and row['M_Score'] >= 3:\n",
    "            return 'At Risk'\n",
    "        elif row['R_Score'] <= 2 and row['F_Score'] >= 2 and row['M_Score'] <= 2:\n",
    "            return 'Cannot Lose Them'\n",
    "        elif row['R_Score'] <= 2 and row['F_Score'] <= 2:\n",
    "            return 'Lost Customers'\n",
    "        else:\n",
    "            return 'Others'\n",
    "    \n",
    "    rfm_df['RFM_Segment'] = rfm_df.apply(assign_segment, axis=1)\n",
    "    \n",
    "    return rfm_df\n",
    "\n",
    "# Apply RFM segmentation\n",
    "rfm_segmented = create_rfm_segments(rfm_data.copy())\n",
    "\n",
    "# Display segment distribution\n",
    "segment_dist = rfm_segmented['RFM_Segment'].value_counts()\n",
    "print(\"üéØ RFM SEGMENT DISTRIBUTION:\")\n",
    "print(\"=\" * 40)\n",
    "for segment, count in segment_dist.items():\n",
    "    percentage = (count / len(rfm_segmented)) * 100\n",
    "    print(f\"{segment:<20}: {count:>4} ({percentage:>5.1f}%)\")\n",
    "\n",
    "# Visualize RFM segments\n",
    "fig = px.pie(\n",
    "    values=segment_dist.values,\n",
    "    names=segment_dist.index,\n",
    "    title='Customer Segments Distribution (RFM Analysis)',\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM Segment Analysis\n",
    "def analyze_rfm_segments(rfm_df):\n",
    "    \"\"\"Analyze characteristics of each RFM segment\"\"\"\n",
    "    \n",
    "    segment_analysis = rfm_df.groupby('RFM_Segment').agg({\n",
    "        'Recency': ['mean', 'median'],\n",
    "        'Frequency': ['mean', 'median'],\n",
    "        'Monetary': ['mean', 'median'],\n",
    "        'RFM_Segment': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    segment_analysis.columns = ['Recency_Mean', 'Recency_Median', 'Frequency_Mean', 'Frequency_Median', \n",
    "                               'Monetary_Mean', 'Monetary_Median', 'Customer_Count']\n",
    "    \n",
    "    return segment_analysis\n",
    "\n",
    "segment_stats = analyze_rfm_segments(rfm_segmented)\n",
    "print(\"üìä SEGMENT CHARACTERISTICS:\")\n",
    "display(segment_stats)\n",
    "\n",
    "# Create segment comparison visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Average Recency by Segment', 'Average Frequency by Segment', \n",
    "                   'Average Monetary by Segment', 'Customer Count by Segment']\n",
    ")\n",
    "\n",
    "# Recency\n",
    "fig.add_trace(\n",
    "    go.Bar(x=segment_stats.index, y=segment_stats['Recency_Mean'], name='Recency'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Frequency\n",
    "fig.add_trace(\n",
    "    go.Bar(x=segment_stats.index, y=segment_stats['Frequency_Mean'], name='Frequency'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Monetary\n",
    "fig.add_trace(\n",
    "    go.Bar(x=segment_stats.index, y=segment_stats['Monetary_Mean'], name='Monetary'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Customer Count\n",
    "fig.add_trace(\n",
    "    go.Bar(x=segment_stats.index, y=segment_stats['Customer_Count'], name='Count'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=800, title_text=\"RFM Segment Analysis\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for K-means clustering\n",
    "def prepare_clustering_data(rfm_df):\n",
    "    \"\"\"Prepare and scale data for clustering\"\"\"\n",
    "    \n",
    "    # Select features for clustering\n",
    "    clustering_features = rfm_df[['Recency', 'Frequency', 'Monetary']].copy()\n",
    "    \n",
    "    # Handle outliers (cap at 95th percentile)\n",
    "    for col in clustering_features.columns:\n",
    "        cap_value = clustering_features[col].quantile(0.95)\n",
    "        clustering_features[col] = np.where(clustering_features[col] > cap_value, cap_value, clustering_features[col])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(clustering_features)\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=clustering_features.columns)\n",
    "    \n",
    "    return scaled_df, scaler, clustering_features\n",
    "\n",
    "scaled_data, scaler, original_features = prepare_clustering_data(rfm_segmented)\n",
    "print(f\"‚úÖ Clustering data prepared: {scaled_data.shape}\")\n",
    "print(f\"Features: {list(scaled_data.columns)}\")\n",
    "\n",
    "# Show scaling effect\n",
    "print(\"\\nüìä SCALING COMPARISON:\")\n",
    "print(\"Original data:\")\n",
    "display(original_features.describe())\n",
    "print(\"\\nScaled data:\")\n",
    "display(scaled_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters\n",
    "def find_optimal_clusters(data, max_clusters=10):\n",
    "    \"\"\"Find optimal number of clusters using elbow method and silhouette score\"\"\"\n",
    "    \n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    K_range = range(2, max_clusters + 1)\n",
    "    \n",
    "    for k in K_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(data)\n",
    "        \n",
    "        inertias.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(data, kmeans.labels_))\n",
    "    \n",
    "    return K_range, inertias, silhouette_scores\n",
    "\n",
    "# Find optimal clusters\n",
    "k_range, inertias, sil_scores = find_optimal_clusters(scaled_data)\n",
    "\n",
    "# Plot elbow curve and silhouette scores\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Elbow Method', 'Silhouette Score']\n",
    ")\n",
    "\n",
    "# Elbow method\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(k_range), y=inertias, mode='lines+markers', name='Inertia'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Silhouette score\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(k_range), y=sil_scores, mode='lines+markers', name='Silhouette Score'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Number of Clusters (k)\")\n",
    "fig.update_yaxes(title_text=\"Inertia\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
    "fig.update_layout(height=400, title_text=\"Optimal Number of Clusters Analysis\")\n",
    "fig.show()\n",
    "\n",
    "# Find best k based on silhouette score\n",
    "best_k = k_range[np.argmax(sil_scores)]\n",
    "best_silhouette = max(sil_scores)\n",
    "\n",
    "print(f\"üìä OPTIMAL CLUSTERING RESULTS:\")\n",
    "print(f\"Best number of clusters: {best_k}\")\n",
    "print(f\"Best silhouette score: {best_silhouette:.3f}\")\n",
    "\n",
    "# Show silhouette scores for each k\n",
    "print(\"\\nSilhouette scores by k:\")\n",
    "for k, score in zip(k_range, sil_scores):\n",
    "    print(f\"k={k}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering with optimal k\n",
    "optimal_k = best_k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Add cluster labels to original data\n",
    "rfm_clustered = rfm_segmented.copy()\n",
    "rfm_clustered['KMeans_Cluster'] = cluster_labels\n",
    "\n",
    "# Analyze K-means clusters\n",
    "kmeans_analysis = rfm_clustered.groupby('KMeans_Cluster').agg({\n",
    "    'Recency': ['mean', 'std'],\n",
    "    'Frequency': ['mean', 'std'],\n",
    "    'Monetary': ['mean', 'std'],\n",
    "    'KMeans_Cluster': 'count'\n",
    "}).round(2)\n",
    "\n",
    "kmeans_analysis.columns = ['Recency_Mean', 'Recency_Std', 'Frequency_Mean', 'Frequency_Std',\n",
    "                          'Monetary_Mean', 'Monetary_Std', 'Customer_Count']\n",
    "\n",
    "print(f\"üéØ K-MEANS CLUSTERING RESULTS (k={optimal_k}):\")\n",
    "display(kmeans_analysis)\n",
    "\n",
    "# Visualize clusters in 3D\n",
    "fig = px.scatter_3d(\n",
    "    rfm_clustered,\n",
    "    x='Recency',\n",
    "    y='Frequency', \n",
    "    z='Monetary',\n",
    "    color='KMeans_Cluster',\n",
    "    title=f'K-Means Customer Clusters (k={optimal_k})',\n",
    "    labels={'color': 'Cluster'}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Show cluster distribution\n",
    "cluster_dist = rfm_clustered['KMeans_Cluster'].value_counts().sort_index()\n",
    "print(f\"\\nüìä CLUSTER DISTRIBUTION:\")\n",
    "for cluster, count in cluster_dist.items():\n",
    "    percentage = (count / len(rfm_clustered)) * 100\n",
    "    print(f\"Cluster {cluster}: {count:>4} customers ({percentage:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering\n",
    "def perform_hierarchical_clustering(data, n_clusters=None, sample_size=500):\n",
    "    \"\"\"Perform hierarchical clustering with dendrogram visualization\"\"\"\n",
    "    \n",
    "    # Sample data for visualization if too large\n",
    "    if len(data) > sample_size:\n",
    "        sample_idx = np.random.choice(len(data), sample_size, replace=False)\n",
    "        data_sample = data.iloc[sample_idx]\n",
    "        print(f\"üìä Using sample of {sample_size} customers for dendrogram visualization\")\n",
    "    else:\n",
    "        data_sample = data\n",
    "    \n",
    "    # Create dendrogram\n",
    "    linkage_matrix = linkage(data_sample, method='ward')\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    dendrogram(linkage_matrix, truncate_mode='level', p=5)\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('Sample Index or (Cluster Size)')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.show()\n",
    "    \n",
    "    # Apply hierarchical clustering to full dataset\n",
    "    if n_clusters is None:\n",
    "        n_clusters = optimal_k  # Use same as K-means for comparison\n",
    "    \n",
    "    hierarchical = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "    hierarchical_labels = hierarchical.fit_predict(data)\n",
    "    \n",
    "    return hierarchical_labels\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "hierarchical_labels = perform_hierarchical_clustering(scaled_data, optimal_k)\n",
    "\n",
    "# Add hierarchical cluster labels\n",
    "rfm_clustered['Hierarchical_Cluster'] = hierarchical_labels\n",
    "\n",
    "# Analyze hierarchical clusters\n",
    "hierarchical_analysis = rfm_clustered.groupby('Hierarchical_Cluster').agg({\n",
    "    'Recency': ['mean', 'std'],\n",
    "    'Frequency': ['mean', 'std'],\n",
    "    'Monetary': ['mean', 'std'],\n",
    "    'Hierarchical_Cluster': 'count'\n",
    "}).round(2)\n",
    "\n",
    "hierarchical_analysis.columns = ['Recency_Mean', 'Recency_Std', 'Frequency_Mean', 'Frequency_Std',\n",
    "                                'Monetary_Mean', 'Monetary_Std', 'Customer_Count']\n",
    "\n",
    "print(f\"üå≥ HIERARCHICAL CLUSTERING RESULTS:\")\n",
    "display(hierarchical_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Segmentation Comparison and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different segmentation methods\n",
    "def compare_segmentation_methods(df):\n",
    "    \"\"\"Compare RFM, K-means, and Hierarchical clustering results\"\"\"\n",
    "    \n",
    "    comparison_results = {\n",
    "        'Method': ['RFM Segments', 'K-Means', 'Hierarchical'],\n",
    "        'Number of Segments': [df['RFM_Segment'].nunique(), \n",
    "                              df['KMeans_Cluster'].nunique(), \n",
    "                              df['Hierarchical_Cluster'].nunique()],\n",
    "        'Silhouette Score': []\n",
    "    }\n",
    "    \n",
    "    # Calculate silhouette scores\n",
    "    methods_data = {\n",
    "        'RFM': df['RFM_Segment'].astype('category').cat.codes,\n",
    "        'KMeans': df['KMeans_Cluster'],\n",
    "        'Hierarchical': df['Hierarchical_Cluster']\n",
    "    }\n",
    "    \n",
    "    for method, labels in methods_data.items():\n",
    "        try:\n",
    "            score = silhouette_score(scaled_data, labels)\n",
    "            comparison_results['Silhouette Score'].append(score)\n",
    "        except:\n",
    "            comparison_results['Silhouette Score'].append(np.nan)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    return comparison_df\n",
    "\n",
    "# Compare methods\n",
    "comparison = compare_segmentation_methods(rfm_clustered)\n",
    "print(\"üîç SEGMENTATION METHODS COMPARISON:\")\n",
    "display(comparison)\n",
    "\n",
    "# Cross-tabulation between methods\n",
    "print(\"\\nüîÑ RFM vs K-Means Segments:\")\n",
    "rfm_kmeans_crosstab = pd.crosstab(rfm_clustered['RFM_Segment'], rfm_clustered['KMeans_Cluster'])\n",
    "display(rfm_kmeans_crosstab)\n",
    "\n",
    "print(\"\\nüîÑ K-Means vs Hierarchical Clusters:\")\n",
    "kmeans_hierarchical_crosstab = pd.crosstab(rfm_clustered['KMeans_Cluster'], rfm_clustered['Hierarchical_Cluster'])\n",
    "display(kmeans_hierarchical_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segmentation comparison\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['RFM Segments', 'K-Means Clusters', 'Hierarchical Clusters', 'Segment Sizes'],\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}],\n",
    "           [{'type': 'scatter3d'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# RFM Segments 3D\n",
    "for i, segment in enumerate(rfm_clustered['RFM_Segment'].unique()):\n",
    "    segment_data = rfm_clustered[rfm_clustered['RFM_Segment'] == segment]\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=segment_data['Recency'],\n",
    "            y=segment_data['Frequency'],\n",
    "            z=segment_data['Monetary'],\n",
    "            mode='markers',\n",
    "            name=segment,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# K-Means Clusters 3D\n",
    "for cluster in rfm_clustered['KMeans_Cluster'].unique():\n",
    "    cluster_data = rfm_clustered[rfm_clustered['KMeans_Cluster'] == cluster]\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=cluster_data['Recency'],\n",
    "            y=cluster_data['Frequency'],\n",
    "            z=cluster_data['Monetary'],\n",
    "            mode='markers',\n",
    "            name=f'K-Means {cluster}',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Hierarchical Clusters 3D\n",
    "for cluster in rfm_clustered['Hierarchical_Cluster'].unique():\n",
    "    cluster_data = rfm_clustered[rfm_clustered['Hierarchical_Cluster'] == cluster]\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=cluster_data['Recency'],\n",
    "            y=cluster_data['Frequency'],\n",
    "            z=cluster_data['Monetary'],\n",
    "            mode='markers',\n",
    "            name=f'Hierarchical {cluster}',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Segment sizes comparison\n",
    "methods = ['RFM', 'K-Means', 'Hierarchical']\n",
    "segment_counts = [\n",
    "    len(rfm_clustered['RFM_Segment'].unique()),\n",
    "    len(rfm_clustered['KMeans_Cluster'].unique()),\n",
    "    len(rfm_clustered['Hierarchical_Cluster'].unique())\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=methods, y=segment_counts, name='Segment Count'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Segmentation Methods Comparison\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Customer Personas and Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer personas based on RFM segments\n",
    "def create_customer_personas(rfm_df):\n",
    "    \"\"\"Create detailed customer personas for each segment\"\"\"\n",
    "    \n",
    "    personas = {\n",
    "        'Champions': {\n",
    "            'description': 'Best customers - high value, frequent purchases, recent activity',\n",
    "            'characteristics': ['High spending', 'Regular purchases', 'Recently active', 'Highly engaged'],\n",
    "            'strategy': 'Reward and retain',\n",
    "            'actions': ['VIP treatment', 'Exclusive offers', 'Early access', 'Loyalty rewards']\n",
    "        },\n",
    "        'Loyal Customers': {\n",
    "            'description': 'Consistent customers with good value and regular engagement',\n",
    "            'characteristics': ['Moderate to high spending', 'Regular engagement', 'Predictable behavior'],\n",
    "            'strategy': 'Maintain relationship and increase value',\n",
    "            'actions': ['Cross-sell', 'Upsell', 'Personalization', 'Relationship building']\n",
    "        },\n",
    "        'New Customers': {\n",
    "            'description': 'Recent customers with potential for growth',\n",
    "            'characteristics': ['Recent first purchase', 'Low frequency', 'Testing the waters'],\n",
    "            'strategy': 'Nurture and convert to loyal',\n",
    "            'actions': ['Welcome series', 'Education', 'Support', 'Incentives for repeat purchase']\n",
    "        },\n",
    "        'Potential Loyalists': {\n",
    "            'description': 'Customers showing signs of increased engagement',\n",
    "            'characteristics': ['Increasing activity', 'Good value potential', 'Responsive to offers'],\n",
    "            'strategy': 'Develop into loyal customers',\n",
    "            'actions': ['Targeted offers', 'Engagement campaigns', 'Value demonstration']\n",
    "        },\n",
    "        'At Risk': {\n",
    "            'description': 'Previously good customers showing declining engagement',\n",
    "            'characteristics': ['Declining frequency', 'Haven\\'t purchased recently', 'High historical value'],\n",
    "            'strategy': 'Win-back campaigns',\n",
    "            'actions': ['Re-engagement offers', 'Surveys', 'Personal outreach', 'Special incentives']\n",
    "        },\n",
    "        'Cannot Lose Them': {\n",
    "            'description': 'High-value customers at risk of churning',\n",
    "            'characteristics': ['High historical spend', 'Infrequent recent activity', 'High churn risk'],\n",
    "            'strategy': 'Immediate intervention required',\n",
    "            'actions': ['Personal contact', 'Exclusive offers', 'Account management', 'Problem resolution']\n",
    "        },\n",
    "        'Lost Customers': {\n",
    "            'description': 'Customers who have likely churned',\n",
    "            'characteristics': ['No recent activity', 'Low engagement', 'Minimal historical value'],\n",
    "            'strategy': 'Reactivation or let go',\n",
    "            'actions': ['Win-back campaigns', 'Surveys', 'Minimal investment', 'Learning from churn']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return personas\n",
    "\n",
    "# Generate personas\n",
    "personas = create_customer_personas(rfm_segmented)\n",
    "\n",
    "# Display persona details for each segment found in data\n",
    "active_segments = rfm_segmented['RFM_Segment'].unique()\n",
    "\n",
    "print(\"üë• CUSTOMER PERSONAS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for segment in active_segments:\n",
    "    if segment in personas:\n",
    "        persona = personas[segment]\n",
    "        segment_size = (rfm_segmented['RFM_Segment'] == segment).sum()\n",
    "        segment_pct = (segment_size / len(rfm_segmented)) * 100\n",
    "        \n",
    "        print(f\"\\nüéØ {segment.upper()} ({segment_size} customers, {segment_pct:.1f}%)\")\n",
    "        print(f\"Description: {persona['description']}\")\n",
    "        print(f\"Strategy: {persona['strategy']}\")\n",
    "        print(\"Key Actions:\")\n",
    "        for action in persona['actions']:\n",
    "            print(f\"  ‚Ä¢ {action}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate business impact metrics\n",
    "def calculate_business_impact(rfm_df):\n",
    "    \"\"\"Calculate business impact metrics for each segment\"\"\"\n",
    "    \n",
    "    segment_impact = rfm_df.groupby('RFM_Segment').agg({\n",
    "        'Monetary': ['sum', 'mean'],\n",
    "        'Frequency': 'mean',\n",
    "        'Recency': 'mean',\n",
    "        'RFM_Segment': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    segment_impact.columns = ['Total_Revenue', 'Avg_Revenue_Per_Customer', 'Avg_Frequency', 'Avg_Recency', 'Customer_Count']\n",
    "    \n",
    "    # Calculate revenue share\n",
    "    total_revenue = segment_impact['Total_Revenue'].sum()\n",
    "    segment_impact['Revenue_Share_Pct'] = (segment_impact['Total_Revenue'] / total_revenue * 100).round(1)\n",
    "    \n",
    "    # Calculate customer share\n",
    "    total_customers = segment_impact['Customer_Count'].sum()\n",
    "    segment_impact['Customer_Share_Pct'] = (segment_impact['Customer_Count'] / total_customers * 100).round(1)\n",
    "    \n",
    "    # Sort by total revenue\n",
    "    segment_impact = segment_impact.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    return segment_impact\n",
    "\n",
    "# Calculate business impact\n",
    "business_impact = calculate_business_impact(rfm_segmented)\n",
    "\n",
    "print(\"üíº BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "display(business_impact)\n",
    "\n",
    "# Visualize business impact\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Revenue Share by Segment', 'Customer Share by Segment', \n",
    "                   'Revenue vs Customer Share', 'Average Revenue per Customer']\n",
    ")\n",
    "\n",
    "# Revenue share\n",
    "fig.add_trace(\n",
    "    go.Bar(x=business_impact.index, y=business_impact['Revenue_Share_Pct'], name='Revenue Share'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Customer share\n",
    "fig.add_trace(\n",
    "    go.Bar(x=business_impact.index, y=business_impact['Customer_Share_Pct'], name='Customer Share'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Revenue vs Customer Share scatter\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=business_impact['Customer_Share_Pct'], \n",
    "        y=business_impact['Revenue_Share_Pct'],\n",
    "        mode='markers+text',\n",
    "        text=business_impact.index,\n",
    "        textposition='top center',\n",
    "        name='Segments'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Average revenue per customer\n",
    "fig.add_trace(\n",
    "    go.Bar(x=business_impact.index, y=business_impact['Avg_Revenue_Per_Customer'], name='Avg Revenue'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=800, title_text=\"Business Impact by Customer Segment\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmentation results\n",
    "try:\n",
    "    # Save detailed segmentation results\n",
    "    rfm_clustered.to_csv('../reports/analysis/03_customer_segmentation_results.csv', index=False)\n",
    "    print(\"üíæ Segmentation results saved to ../reports/analysis/03_customer_segmentation_results.csv\")\n",
    "    \n",
    "    # Save business impact analysis\n",
    "    business_impact.to_csv('../reports/analysis/03_business_impact_analysis.csv')\n",
    "    print(\"üíæ Business impact analysis saved to ../reports/analysis/03_business_impact_analysis.csv\")\n",
    "    \n",
    "    # Save segmentation comparison\n",
    "    comparison.to_csv('../reports/analysis/03_segmentation_comparison.csv', index=False)\n",
    "    print(\"üíæ Segmentation comparison saved to ../reports/analysis/03_segmentation_comparison.csv\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Customer segmentation analysis completed successfully!\")\n",
    "    print(\"üöÄ Ready for next notebook: 04_predictive_modeling.ipynb\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not save reports: {e}\")\n",
    "    print(\"üìä Analysis completed - results available in notebook\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã SEGMENTATION ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ RFM Analysis: {rfm_segmented['RFM_Segment'].nunique()} segments identified\")\n",
    "print(f\"‚úÖ K-Means Clustering: {optimal_k} clusters (silhouette score: {best_silhouette:.3f})\")\n",
    "print(f\"‚úÖ Hierarchical Clustering: {rfm_clustered['Hierarchical_Cluster'].nunique()} clusters\")\n",
    "print(f\"‚úÖ Business Impact: Revenue concentration analysis completed\")\n",
    "print(f\"‚úÖ Customer Personas: Actionable strategies developed\")\n",
    "print(\"\\nüéØ Key Recommendation: Focus on Champions and At-Risk segments for maximum impact\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}